---
title: About
---
> Neural Synthesis of Natural Images From Semantically Guided Graphical Representations

In this work, we address the novel problem of generating realistic images through scene autocompletion, in which a user can provide the overall concept of the scene with missing objects and relations. Our goal is to minimize the user effort by alleviating them from specifying each and every minute detail of a scene, which is traditionally captured through object relations in form of a graph. Towards this end we propose our model *Neural Synthesis of Natural Images From Semantically Guided Graphical Representations* , wherein we take an incomplete scene graph from the users, and through our multi-staged pipeline, we autocomplete the scene, infer the layout of the scene, and finally generate the image. In short, our goal is to Generate <span style="color:#2DAD0E">natural looking and coherent</span> images from given (<span style="color:#F86343">incomplete</span>) <span style="color:#4390F8">scene graph</span>. 
<center>
<img src="../images/pipeline.png" alt="pipeline" style="width:600px;"/>
</center>